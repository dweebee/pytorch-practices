{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8ci+ImfutZ/X+S4yWpXOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dweebee/pytorch-practices/blob/main/00_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'''\n",
        "    07-2. 심층신경망(p.411~421)\n",
        "    파이토치\n",
        "'''"
      ],
      "metadata": {
        "id": "NF4OZgWCkFur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 파이토치로 신겸앙 모델 만들기\n",
        "\n",
        " 주소: https://bit.ly/hg2-07-2-pt 접속시 코랩에서 이 절의 코드를 바로 열어 볼 수 있습니다.\n",
        "\n",
        "파이토치의 컴퓨터 비전 라이브러리인 torchvision을 통해 데이터셋을 로드할 수 있습니다."
      ],
      "metadata": {
        "id": "DVlzV1qPM0bF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "wS8MByeJV_oQ",
        "outputId": "ffcf6ed0-1b4d-4487-b8bb-b7ad755bba96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 15.5MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 231kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 4.29MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 204);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "fm_train = FashionMNIST(root='.', train=True, download=True)\n",
        "fm_test = FashionMNIST(root='.', train=False, download=True)\n",
        "\n",
        "type(fm_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torchvision: PyTorch에서 자주 쓰이는 이미지 데이터셋과 전처리 도구를 제공\n",
        "- MNIST처럼 28x28 흑백 이미지지만, 숫자가 아니라 의류(옷) 이미지 데이터셋\n",
        "    - 클래스: 티셔츠, 바지, 스니커즈, 샌들 등 10가지 분류.\n",
        "- root='.': 현재 디렉토리에 클래스명과 동일한 FashionMNIST 폴더를 만들고 그 안에 데이터를 저장하겠다는 의미. 다운된 데이터를 저장할 위치.\n",
        "- download=True: 로컬에 이미 데이터가 있다면 다운로드 하지 않고, 데이터가 없으면 자동으로 다운로드 | 기본값은 False"
      ],
      "metadata": {
        "id": "86U_o4YTp-0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(fm_train.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu97AvvgWjxC",
        "outputId": "95f61b3a-dea9-4bcf-db53-558261394341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor는 파이토치의 기본 데이터 구조.\n",
        "\n",
        "넘파이 배열과 비슷한 인터페이스를 사용."
      ],
      "metadata": {
        "id": "uGyEz2WdNoa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(fm_train.data.shape, fm_test.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFM3AgQ9Wv3D",
        "outputId": "3313464d-290a-49f3-8e87-d902313f9f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch 이미지 텐서의 Shape과 전처리 요약\n",
        "\n",
        "PyTorch에서 이미지 데이터를 모델에 입력하기 위해서는 일정한 텐서 구조와 전처리 방식이 필요하다.\n",
        "\n",
        "---\n",
        "\n",
        "## 기본 텐서 Shape: `(N, C, H, W)`\n",
        "\n",
        "| 차원 | 의미 |\n",
        "|------|------|\n",
        "| `N` | 이미지 수 또는 배치 크기 (`batch size`) |\n",
        "| `C` | 채널 수 (흑백: 1, RGB: 3) |\n",
        "| `H` | 이미지 높이 (Height) |\n",
        "| `W` | 이미지 너비 (Width) |\n",
        "\n",
        "예시:\n",
        "```python\n",
        "x = torch.randn(32, 3, 224, 224)  # 32장의 RGB 이미지\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 왜 `C`가 두 번째일까?\n",
        "\n",
        "- PyTorch는 Channel-first 구조 `(C, H, W)`를 따름\n",
        "- `torch.nn.Conv2d`, `BatchNorm2d` 등 모든 이미지 연산이 이 구조를 전제로 설계됨\n",
        "- `transforms.ToTensor()`를 사용하면 PIL 이미지를 자동으로 `(C, H, W)`로 변환함\n",
        "\n",
        "---\n",
        "\n",
        "## 파인튜닝 시: 사전학습 모델 전처리와 일치해야 함\n",
        "\n",
        "예: `resnet18(pretrained=True)`는 ImageNet 기준으로 학습되었기 때문에 입력 전처리가 반드시 일치해야 함\n",
        "\n",
        "```python\n",
        "transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "```\n",
        "\n",
        "| 요구 조건 | 값 |\n",
        "|-----------|-----|\n",
        "| 크기      | 224×224 |\n",
        "| 채널 수   | 3 (RGB) |\n",
        "| 정규화    | ImageNet 기준 평균과 표준편차\n",
        "\n",
        "---\n",
        "\n",
        "## `N`은 이미지 수? 배치 크기?\n",
        "\n",
        "- 전체 데이터셋: 이미지 수 (`len(dataset)`)\n",
        "- 모델 입력 시: 배치 크기 (`batch_size=32` 등)\n",
        "\n",
        "```python\n",
        "for images, labels in dataloader:\n",
        "    print(images.shape)  # (32, 3, 224, 224)\n",
        "```\n",
        "\n",
        "→ 문맥에 따라 `N`은 이미지 수 또는 배치 크기 둘 다 의미할 수 있다.\n",
        "\n",
        "---\n",
        "\n",
        "## 요약\n",
        "\n",
        "- PyTorch는 `(N, C, H, W)` 형식을 사용한다\n",
        "- `C`는 Conv 연산 특성상 반드시 두 번째에 위치해야 한다\n",
        "- 사전학습 모델을 쓸 경우 입력 전처리를 반드시 맞춰야 한다\n",
        "- `N`은 데이터의 수이자 모델 처리 단위인 배치 크기이다\n"
      ],
      "metadata": {
        "id": "PW_sMrAQuN1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(fm_train.targets.shape, fm_test.targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLbew9roWyYx",
        "outputId": "a303f9de-e7fe-4008-e1a6-d5123e10d977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000]) torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = fm_train.data\n",
        "train_target = fm_train.targets"
      ],
      "metadata": {
        "id": "eSrVYPEpW4l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fm_train.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcKsMPuFXHcL",
        "outputId": "3355da07-d55e-40d2-bcfc-6515e532b6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "           0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,   1,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
              "          36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,   0,   3],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
              "         102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,  15],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  69,\n",
              "         207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88, 172,  66],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0, 200,\n",
              "         232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196, 229,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183,\n",
              "         225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245, 173,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193,\n",
              "         228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243, 202,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12, 219,\n",
              "         220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244,\n",
              "         222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55, 236,\n",
              "         228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,  92,   0],\n",
              "        [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237, 226,\n",
              "         217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,  77,   0],\n",
              "        [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228, 207,\n",
              "         213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244, 159,   0],\n",
              "        [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217, 226,\n",
              "         200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238, 215,   0],\n",
              "        [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200, 159,\n",
              "         245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232, 246,   0],\n",
              "        [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80,\n",
              "         150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0],\n",
              "        [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
              "          65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,  29],\n",
              "        [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198, 213,\n",
              "         240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221, 230,  67],\n",
              "        [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219, 221,\n",
              "         220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205, 206, 115],\n",
              "        [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211, 210,\n",
              "         200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177, 210,  92],\n",
              "        [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189, 188,\n",
              "         193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216, 170,   0],\n",
              "        [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244, 221,\n",
              "         220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 값들은 0 ~ 255 사이의 정수형 (uint8) 값\n",
        "- 실제 이미지 시각화\n",
        "```\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(fm_train.data[0], cmap='gray')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "oQWa0uNByHTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fm_train.data[0].shape #각 이미지에 대한 정답 레이블 (0~9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBk8MoCpXPOX",
        "outputId": "bb7d5482-c5cc-42af-900d-47ad0127e3ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fm_train.targets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPRE3RcnxH0t",
        "outputId": "e975b823-7499-4300-fc8c-ef9167a7135d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fm_train.targets[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2LMW6t3xMfU",
        "outputId": "d4063403-4e83-4bda-84c2-c3a0364f185e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모양(shape)이 없는 0차원 텐서, 즉 스칼라\n",
        "- .item()을 쓰면 스칼라 tensor를 Python 숫자로 변환가능"
      ],
      "metadata": {
        "id": "SrjdkNDJxixX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화\n",
        "train_scaled = train_input / 255.0"
      ],
      "metadata": {
        "id": "YD1drC7FW-Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0~1 범위로 정규화하면: 학습이 더 안정적이고 경사하강법의 수렴 속도도 좋아짐"
      ],
      "metadata": {
        "id": "5heX2xDR3QO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1raWEx6BXWiz",
        "outputId": "cc05f1ee-a12d-40d6-eda6-14afd1a1f023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510, 0.2863, 0.0000,\n",
              "         0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0039,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333, 0.4980, 0.2431,\n",
              "         0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118, 0.0157, 0.0000, 0.0000,\n",
              "         0.0118],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000, 0.6902, 0.5255,\n",
              "         0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.0392,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255, 0.8118, 0.6980,\n",
              "         0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902, 0.3020, 0.5098, 0.2824,\n",
              "         0.0588],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745, 0.8549, 0.8471,\n",
              "         0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725, 0.5529, 0.3451, 0.6745,\n",
              "         0.2588],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098, 0.9137, 0.8980,\n",
              "         0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980, 0.4824, 0.7686, 0.8980,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471, 0.8745, 0.8941,\n",
              "         0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667, 0.8745, 0.9608, 0.6784,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549, 0.8353, 0.7765,\n",
              "         0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745, 0.8627, 0.9529, 0.7922,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314, 0.8549, 0.7529,\n",
              "         0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314, 0.8863, 0.7725, 0.8196,\n",
              "         0.2039],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627, 0.8549, 0.7961,\n",
              "         0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627, 0.9608, 0.4667, 0.6549,\n",
              "         0.2196],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020, 0.8941, 0.9412,\n",
              "         0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510, 0.8510, 0.8196, 0.3608,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745, 0.8706, 0.8588,\n",
              "         0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431, 0.8549, 1.0000, 0.3020,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667, 0.8549, 0.8157,\n",
              "         0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431, 0.8784, 0.9569, 0.6235,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196, 0.7412,\n",
              "         0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039, 0.8275, 0.9020,\n",
              "         0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725, 0.9137, 0.9333, 0.8431,\n",
              "         0.0000],\n",
              "        [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157, 0.8000,\n",
              "         0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569, 0.8078, 0.8745,\n",
              "         1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275, 0.8627, 0.9098, 0.9647,\n",
              "         0.0000],\n",
              "        [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392, 0.8039,\n",
              "         0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000, 0.8980, 0.8667,\n",
              "         0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196, 0.8706, 0.8941, 0.8824,\n",
              "         0.0000],\n",
              "        [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176, 0.9765,\n",
              "         0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863, 0.4157, 0.4588,\n",
              "         0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745, 0.8745, 0.8784, 0.8980,\n",
              "         0.1137],\n",
              "        [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824, 0.8471,\n",
              "         0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647, 0.8902, 0.9608,\n",
              "         0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706, 0.8627, 0.8667, 0.9020,\n",
              "         0.2627],\n",
              "        [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451, 0.7608,\n",
              "         0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255, 0.8824, 0.8471,\n",
              "         0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745, 0.7098, 0.8039, 0.8078,\n",
              "         0.4510],\n",
              "        [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686, 0.8000,\n",
              "         0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686, 0.7608, 0.7490,\n",
              "         0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118, 0.6549, 0.6941, 0.8235,\n",
              "         0.3608],\n",
              "        [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745, 0.6863,\n",
              "         0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765, 0.8000, 0.8196,\n",
              "         0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608, 0.7529, 0.8471, 0.6667,\n",
              "         0.0000],\n",
              "        [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294, 0.9373,\n",
              "         0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569, 0.7490, 0.7020,\n",
              "         0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588, 0.3882, 0.2275, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.2392,\n",
              "         0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "print(train_scaled.shape, val_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ_WzZ8EXE54",
        "outputId": "c91662c8-ec12-42f9-badd-d84a73fbf3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([48000, 28, 28]) torch.Size([12000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S92JiviypFO",
        "outputId": "1d315cf8-e24d-4aae-eb40-cf77f02e6146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 첫 번째 이미지는 28픽셀 × 28픽셀의 2차원 텐서\n",
        "- 채널(C)은 따로 없는데, 이유는 흑백(grayscale)이기 때문\n",
        "- 모델 입력으로 넣기 전에 unsqueeze(0)을 통해 채널 차원을 추가해 (1, 28, 28)으로 만드는 게 일반적\n",
        "```\n",
        "img = fm_train.data[0].unsqueeze(0).float() / 255.0  # (1, 28, 28)\n"
      ],
      "metadata": {
        "id": "MleiP4JSygCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),           # (1) 2D 이미지 → 1D 벡터\n",
        "    nn.Linear(784, 100),    # (2) 입력층 → 은닉층 | 입력 벡터(784차원)를 은닉층(100차원)으로 매핑하는 완전연결층\n",
        "    nn.ReLU(),              # (3) 활성화 함수 | 비선형성 추가\n",
        "    nn.Linear(100, 10)      # (4) 은닉층 → 출력층 | 은닉층 출력을 최종 클래스 10개로 매핑 (소프트맥스 전 단계)\n",
        ")\n"
      ],
      "metadata": {
        "id": "_lL10Y02Xpe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential 클래스 안에 필요한 층을 차례로 나열한다.\n",
        "\n",
        "시작할 때 1차원으로 펴주고, 두 밀집층 사이에 활성화함수 추가.\n",
        "\n",
        "Linear는 밀집층인데, 호출시에는 입력크기와 출력크기(뉴런개수)를 매개변수로 반드시 전달한다.\n",
        "\n",
        "파이토치에서는 활성화함수를 별도의 층으로 추가한다.\n",
        "\n",
        "출력층에 해당하는 두번째 밀집층 다음에 활성화 함수가 없다. 파이토치에서 다중분류시 이를 생략한다."
      ],
      "metadata": {
        "id": "REYXsWtkOZH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchinfo"
      ],
      "metadata": {
        "id": "9lgkV7mfXzXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKGwyCCTYVkx",
        "outputId": "1a15936f-1c3a-4c41-ba8c-16f7571c37c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Sequential                               --\n",
              "├─Flatten: 1-1                           --\n",
              "├─Linear: 1-2                            78,500\n",
              "├─ReLU: 1-3                              --\n",
              "├─Linear: 1-4                            1,010\n",
              "=================================================================\n",
              "Total params: 79,510\n",
              "Trainable params: 79,510\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서 모델 전체 구조 확인시 torchinfo 패키지를 활용한다.\n",
        "\n",
        "입력 크기를 지정하면 입력 데이터가 각 층을 통과할 때 어떻게 크기가 변하는지 확인할 수 있다."
      ],
      "metadata": {
        "id": "69EbPDE6O938"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(32,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0I3Kxlng38Y",
        "outputId": "c1d5be26-79bd-4487-b56d-19c9f53ad267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential                               [32, 10]                  --\n",
              "├─Flatten: 1-1                           [32, 784]                 --\n",
              "├─Linear: 1-2                            [32, 100]                 78,500\n",
              "├─ReLU: 1-3                              [32, 100]                 --\n",
              "├─Linear: 1-4                            [32, 10]                  1,010\n",
              "==========================================================================================\n",
              "Total params: 79,510\n",
              "Trainable params: 79,510\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 2.54\n",
              "==========================================================================================\n",
              "Input size (MB): 0.10\n",
              "Forward/backward pass size (MB): 0.03\n",
              "Params size (MB): 0.32\n",
              "Estimated Total Size (MB): 0.45\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSLDx4xCg8Le",
        "outputId": "9e3998ac-73a1-4159-d428-89dd15847c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "6fqc-utkhBR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batches = int(len(train_scaled)/32)\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for i in range(batches):\n",
        "        inputs = train_scaled[i*32:(i+1)*32].to(device)\n",
        "        targets = train_target[i*32:(i+1)*32].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs) # 내부적으로 __call__ → forward()를 통해 네트워크를 순전파 | outputs는 softmax 되지 않은 raw 출력값, 즉 logits\n",
        "        loss = criterion(outputs, targets) # criterion이 반환하는 값은 배치에 있는 샘플에 대한 손실합이 아니라 '평균'\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/batches:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_scaled = val_scaled.to(device)\n",
        "        val_target = val_target.to(device)\n",
        "        outputs = model(val_scaled)\n",
        "        predicts = torch.argmax(outputs, dim=1)\n",
        "        corrects = (predicts == val_target).sum().item()\n",
        "    acc = corrects / len(val_target)\n",
        "    print(f\"검증 정확도: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oORhsGzmhWaY",
        "outputId": "c1d7ff2c-d081-46dc-d3b9-8fd788cffc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Train Loss: 2.3250\n",
            "검증 정확도: 0.0459\n",
            "Epoch 2/5, Train Loss: 2.3250\n",
            "검증 정확도: 0.0459\n",
            "Epoch 3/5, Train Loss: 2.3250\n",
            "검증 정확도: 0.0459\n",
            "Epoch 4/5, Train Loss: 2.3250\n",
            "검증 정확도: 0.0459\n",
            "Epoch 5/5, Train Loss: 2.3250\n",
            "검증 정확도: 0.0459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logits란?\n",
        "logits는 소프트맥스 함수에 들어가기 전의 값\n",
        "\n",
        "어떤 클래스에 속할 “가능성”을 상대적인 점수로 표현한 것\n",
        "\n",
        "보통 [-∞, +∞] 범위의 실수값\n",
        "\n",
        "정규화된 확률은 아니지만, 순서/크기 관계는 중요"
      ],
      "metadata": {
        "id": "v522HSe9HMe4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CFQaKGWkmri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}